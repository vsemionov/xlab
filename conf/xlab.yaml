seed_everything: 42
trainer:
  logger:  # TODO: configure
    class_path: CSVLogger
    init_args:
      save_dir: .
  callbacks:  # TODO: model checkpoint (check saved best metric), early stopping?, lr monitor, save config (to log config)
    - RichModelSummary
    - XLabRichProgressBar
    - LearningRateMonitor
    - class_path: ModelCheckpoint
      init_args:
        monitor: val_loss
        mode: min
        save_last: true
        save_top_k: 10
        every_n_epochs: null
        every_n_train_steps: null
  max_epochs: 20
  deterministic: null  # TODO: check speed and enable?
  benchmark: null
model:
  max_len: 128
  d_model: 128
  position: xlab.transformers.PositionalEncoding
  n_blocks: 2
  n_heads: 2
  d_ff: 256
  dropout: 0.1
  prenorm: false
  postnorm: false
  norm: torch.nn.LayerNorm
  activation: torch.nn.ReLU
  attn_drop: true
  ff_drop: true
data:
  path: wikipedia
  name: 20220301.simple
  splits:
    train: 0.1
    val: 0.05
    test: 0.05
    predict: 0.05
  tokenizer: basic_english
  language: en
  max_tokens: 10000
  column: text
  num_proc: 4
  progress: tqdm
  batch_size: 32
  num_workers: 4
  persistent_workers: false
optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 3e-4
    betas:
      - 0.9
      - 0.999
    weight_decay: 0.0
lr_scheduler: null  # TODO
ckpt_path: null
